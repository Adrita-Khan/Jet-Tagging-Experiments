conv1.linear.weight: torch.float32
conv1.linear.bias: torch.float32
conv2.linear.weight: torch.float32
conv2.linear.bias: torch.float32
conv3.linear.weight: torch.float32
conv3.linear.bias: torch.float32
edgeconv1.theta.weight: torch.float32
edgeconv1.theta.bias: torch.float32
edgeconv1.phi.weight: torch.float32
edgeconv1.phi.bias: torch.float32
edgeconv2.theta.weight: torch.float32
edgeconv2.theta.bias: torch.float32
edgeconv2.phi.weight: torch.float32
edgeconv2.phi.bias: torch.float32
fc.weight: torch.float32
fc.bias: torch.float32
  0%|                                                                                                                                                                             | 0/2499 [00:00<?, ?it/s]/media/drive1/jettag/env_jet/lib/python3.10/site-packages/dgl/nn/pytorch/conv/chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.
  dgl_warning(
Traceback (most recent call last):                                                                                                                                                                         
  File "/media/drive1/jettag/Jet-Tagging/raqib-pcn-experiments/training-experiments/GNNVM.py", line 292, in <module>
    logits = model(graph)
  File "/media/drive1/jettag/env_jet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/drive1/jettag/env_jet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1603, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/media/drive1/jettag/Jet-Tagging/raqib-pcn-experiments/training-experiments/GNNVM.py", line 162, in forward
    h = F.relu(self.edgeconv1(g, h))
  File "/media/drive1/jettag/env_jet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/drive1/jettag/env_jet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/drive1/jettag/env_jet/lib/python3.10/site-packages/dgl/nn/pytorch/conv/edgeconv.py", line 158, in forward
    raise DGLError(
dgl._ffi.base.DGLError: There are 0-in-degree nodes in the graph, output for those nodes will be invalid. This is harmful for some applications, causing silent performance regression. Adding self-loop on the input graph by calling `g = dgl.add_self_loop(g)` will resolve the issue. Setting ``allow_zero_in_degree`` to be `True` when constructing this module will suppress the check and let the code run.
Traceback (most recent call last):
  File "/media/drive1/jettag/Jet-Tagging/raqib-pcn-experiments/training-experiments/GNNVM.py", line 292, in <module>
    logits = model(graph)
  File "/media/drive1/jettag/env_jet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/drive1/jettag/env_jet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1603, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/media/drive1/jettag/Jet-Tagging/raqib-pcn-experiments/training-experiments/GNNVM.py", line 162, in forward
    h = F.relu(self.edgeconv1(g, h))
  File "/media/drive1/jettag/env_jet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/media/drive1/jettag/env_jet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/media/drive1/jettag/env_jet/lib/python3.10/site-packages/dgl/nn/pytorch/conv/edgeconv.py", line 158, in forward
    raise DGLError(
dgl._ffi.base.DGLError: There are 0-in-degree nodes in the graph, output for those nodes will be invalid. This is harmful for some applications, causing silent performance regression. Adding self-loop on the input graph by calling `g = dgl.add_self_loop(g)` will resolve the issue. Setting ``allow_zero_in_degree`` to be `True` when constructing this module will suppress the check and let the code run.
